# ES核心概念

集群，节点，索引，类型，文档，分片，映射

elasticsearch是面向文档，关系型数据库和elasticsearch 客观的对比!。ES一切都是JSON

| RelationDB         | Elastic Search  |
| ------------------ | --------------- |
| 数据库（database） | 索引（indices） |
| 表（table）        | types（弃用）   |
| 行（rows）         | documents       |
| 字段（columns）    | fields          |

elasticsearch(集群)中可以包含多个索引(数据库)，每个索引中可以包含多个类型(表)，每个类型下又包含多个文档(行)，每个文档中又包含多个字段(列)。

物理设计

elasticsearch在后台把每个**索引划分成多个分片**，每分分片可以在集群中的不同服务器间迁移。

逻辑设计

一个索引类型中，包含多个文档，比如说文档1，文档2。当我们索引一篇文档时，可以通过这样的一各顺序找到它:索引>类型>文档ID，通过这个组合我们就能索引到某个具体的文档。

注意:ID不必是整数，实际上它是个字符串。

- 文档：
  之前说elasticsearch是面向文档的，那么就意味着索引和搜索数据的最小单位是文档，elasticsearch中，文档有几个重要属性:
  · 自我包含，一篇文档同时包含字段和对应的值，也就是同时包含`key:vallue` !（一行数据统称文档）
  · 可以是层次型的，一个文档中包含自文档，复杂的逻辑实体就是这么来的!【就是一个JSON对象！java当中通过fastjson自动转换！】
  · 灵活的结构，文档不依赖预先定义的模式，我们知道关系型数据库中，要提前定义字段才能使用，在elasticsearch中，对于字段是非常灵活的，有时候，我们可以忽略该字段，或者动态的添加一个新的字段。
  尽管我们可以随意的新增或者忽略某个字段，但是，每个字段的类型非常重要，比如一个年龄字段类型，可以是字符串也可以是整形。因为elasticsearch会保存字段和类型之间的映射及其他的设置。这种映射具体到每个映射的每种类型，这也是为什么在elasticsearch中，类型有时候也称为映射类型。
- 类型：（ES8当中已经弃用-了解即可）
  类型是文档的逻辑容器，就像关系型数据库一样，表格是行的容器。类型中对于字段的定义称为映射，比如name映射为字符串类型。我们说文档是无模式的，它们不需要拥有映射中所定义的所有字段，比如新增一个字段，那么elasticsearch是怎么做的呢?elasticsearch会自动的将新字段加入映射，但是这个字段的不确定它是什么类型，elasticsearch就开始猜，如果这个值是18，那么elasticsearch会认为它是整形。但是elasticsearch也可能猜不对，所以最安全的方式就是提前定义好所需要的映射，这点跟关系型数据库殊途同归了，先定义好字段，然后再使用，别整什么幺蛾子。
- 索引：
  索引是映射类型的容器，elasticsearch中的索引是一个非常大的文档集合（相当于数据库）。
  索引存储了映射类型的字段和其他设置。然后它们被存储到了各个分片上了。我们来研究下分片是如何工作的。

一个集群至少有一个节点，而一个节点就是一个elasricsearch进程，节点可以有多个索引默认的，如果你创建索引，那么索引将会有个5个分片( primary shard ,又称主分片)构成的，每一个主分片会有一个副本( replica shard ,又称复制分片)

实际上，一个分片是一个Lucene索引，一个包含倒排索引的文件目录，倒排索引的结构使得elasticsearch在不扫描全部文档的情况下，就能告诉你哪些文档包含特定的关键字。不过，等等，倒排索引是什么鬼?

## 倒排索引

elasticsearch使用的是一种称为倒排索引的结构，采用Lucene倒排索作为底层。这种结构适用于快速的全文搜索，一个索引由文档中所有不重复的列表构成，对于每一个词，都有一个包含它的文档列表。

![在这里插入图片描述](https://cdn.jsdelivr.net/gh/522923331/typora-image/img/f71e0cfd6ec2422c9f97644888e4d1c1.png)

边博客文章为一行为一个文档，右边将对应的文档进行倒排索引，找到对应关键字，所在的文档id进行统计。

如果要搜索含有python标签的文章，那相对于查找所有原始数据而言，查找倒排索引后的数据将会快的多。
只需要查看标签这一栏，然后获取相关的文章ID即可。

## elasticsearch的索引和Lucene的索引对比

在elasticsearch中，索引这个词被频繁使用，这就是术语的使用。

在elasticsearch中，索引被分为多个分片，每份分片是一个Lucene的索引。
所以一个elasticsearch索引是由多个Lucene索引组成的。

别问为什么，谁让elasticsearch使用Lucene作为底层呢!如无特指，说起索引都是指elasticsearch的索引。

# IK分词器

## 1.什么是IK分词器

分词:即把一段中文或者别的划分成一个个的关键字，我们在搜索时候会把自己的信息进行分词，会把数据库中或者索引库中的数据进行分词，然后进行一个匹配操作，默认的中文分词是将每个字看成一个词，比如“我爱中国"会被分为"我"∵"爱"“中”"国”，这显然是不符合要求的，所以我们需要安装中文分词器ik来解决这个问题。

如果要使用中文，建议使用IK分词器。

IK提供了两个分词算法: ik_smart和ik_max_word ，其中ik_smart为最少切分，ik_max_word为最细粒度划分!

## 2.安装启动IK分词器

下载IK分词器：https://github.com/medcl/elasticsearch-analysis-ik/releases

版本保持跟es版本一致即可。elasticsearch-analysis-ik-8.7.0.zip

将其放入ElasticSearch 的插件当中，在ElasticSearch的plugins目录下解压即可：

...plugins:

​	-elasticsearch-analysis-ik-8.7.0

重新启动ElasticSearch ，elasticsearch head，Kibana

在重新启动ElasticSearch 的时候我们可以看到IK分词器被加载了

```yaml
#loaded plugin [analysis-ik]
```

## 3.elasticsearch-plugin

通过elasticsearch-plugin命令查看加载进来的插件
列出elasticsearch安装的插件列表
进入es的bin目录下:

```shell
deMacBook-Air bin % ./elasticsearch-plugin list
elasticsearch-analysis-ik-8.7.0
```

我们可以看到已经安装成功了ik分词器的插件。

## 4.使用Kibana进行测试

打开kibana--》home--》开发工具

### a.使用ik_smart分词器（最少切分）

```json
GET _analyze
{
  "analyzer":"ik_smart",
  "text":"我爱中国共产党"
}
```

输出：

```json
{
  "tokens": [
    {
      "token": "我",
      "start_offset": 0,
      "end_offset": 1,
      "type": "CN_CHAR",
      "position": 0
    },
    {
      "token": "爱",
      "start_offset": 1,
      "end_offset": 2,
      "type": "CN_CHAR",
      "position": 1
    },
    {
      "token": "中国共产党",
      "start_offset": 2,
      "end_offset": 7,
      "type": "CN_WORD",
      "position": 2
    }
  ]
}
```

### b.	使用ik_max_word（最细粒度划分）

```json
GET _analyze
{
  "analyzer":"ik_max_word",
  "text":"我爱中国共产党"
}
```

```json
{
  "tokens": [
    {
      "token": "我",
      "start_offset": 0,
      "end_offset": 1,
      "type": "CN_CHAR",
      "position": 0
    },
    {
      "token": "爱",
      "start_offset": 1,
      "end_offset": 2,
      "type": "CN_CHAR",
      "position": 1
    },
    {
      "token": "中国共产党",
      "start_offset": 2,
      "end_offset": 7,
      "type": "CN_WORD",
      "position": 2
    },
    {
      "token": "中国",
      "start_offset": 2,
      "end_offset": 4,
      "type": "CN_WORD",
      "position": 3
    },
    {
      "token": "国共",
      "start_offset": 3,
      "end_offset": 5,
      "type": "CN_WORD",
      "position": 4
    },
    {
      "token": "共产党",
      "start_offset": 4,
      "end_offset": 7,
      "type": "CN_WORD",
      "position": 5
    },
    {
      "token": "共产",
      "start_offset": 4,
      "end_offset": 6,
      "type": "CN_WORD",
      "position": 6
    },
    {
      "token": "党",
      "start_offset": 6,
      "end_offset": 7,
      "type": "CN_CHAR",
      "position": 7
    }
  ]
}
```

如果我们想要让某个词不做拆分，那么可以通过将对应的数据添加到分词器的字典当中来实现。

比如中华大地，默认情况下是分成两个词，如果我们不想把这个分词，就可以做自定义字典来实现

```json
GET _analyze
{
  "analyzer":"ik_smart",
  "text":"我爱中华大地"
}
```

```json
{
  "tokens": [
    {
      "token": "我",
      "start_offset": 0,
      "end_offset": 1,
      "type": "CN_CHAR",
      "position": 0
    },
    {
      "token": "爱",
      "start_offset": 1,
      "end_offset": 2,
      "type": "CN_CHAR",
      "position": 1
    },
    {
      "token": "中华",
      "start_offset": 2,
      "end_offset": 4,
      "type": "CN_WORD",
      "position": 2
    },
    {
      "token": "大地",
      "start_offset": 4,
      "end_offset": 6,
      "type": "CN_WORD",
      "position": 3
    }
  ]
}
```





## 5.自定义分词字典

进入ik分词的config目录，创建自定义词典：

比如创建一个my.dic字典文件

编辑字典，填写对应的内容

```shell
touch my.dic
vim my.dic
#在打开的文件中输入对应的中文，如果有多个，换行输入就行了
中华大地
```

然后修改本config目录下的IKAnalyzer.cfg.xml

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
<properties>
        <comment>IK Analyzer 扩展配置</comment>
        <!--用户可以在这里配置自己的扩展字典 -->
        <entry key="ext_dict">my.dic</entry>
         <!--用户可以在这里配置自己的扩展停止词字典-->
        <entry key="ext_stopwords"></entry>
        <!--用户可以在这里配置远程扩展字典 -->
        <!-- <entry key="remote_ext_dict">words_location</entry> -->
        <!--用户可以在这里配置远程扩展停止词字典-->
        <!-- <entry key="remote_ext_stopwords">words_location</entry> -->
</properties>
```

然后重新启动ES服务器，再次测试

```json
{
  "tokens": [
    {
      "token": "我",
      "start_offset": 0,
      "end_offset": 1,
      "type": "CN_CHAR",
      "position": 0
    },
    {
      "token": "爱",
      "start_offset": 1,
      "end_offset": 2,
      "type": "CN_CHAR",
      "position": 1
    },
    {
      "token": "中华大地",
      "start_offset": 2,
      "end_offset": 6,
      "type": "CN_WORD",
      "position": 2
    }
  ]
}
```



# ElasticSearch 索引的基本操作

## 1、Rest风格说明

一种软件架构风格，而不是标准，只是提供了一组设计原则和约束条件。它主要用于客户端和服务器交互类的软件。基于这个风格设计的软件可以更简洁，更有层次，更易于实现缓存等机制。
基本Rest命令说明

| method | url地址                                             | 描述                   |
| ------ | --------------------------------------------------- | ---------------------- |
| PUT    | localhost:9200/索引名称/类型名称/文档id             | 创建文档（指定文档id ) |
| POST   | localhost:9200/索引名称/类型名称                    | 创建文档（随机文档id ) |
| POST   | localhost:9200/索引名称/类型名称/文档id/**_update** | 修改文档               |
| POST   | localhost:9200/索引名称/类型名称/**_search**        | 查询所有数据           |
| GET    | localhost:9200/索引名称/类型名称/文档id             | 查询文档通过文档id     |
| DELETE | localhost:9200/索引名称/类型名称/文档id             | 删除文档               |

## 2、创建索引

打开elasticsearch head，集群概览下，可以看到之前建立的test索引，我们可以通过界面删除这个索引。

创建索引结构：

```
PUT /索引名/默认数据类型/id
{请求体}
```

打开kibana，输入一下内容创建索引：

```JSON
PUT /test1/_doc/1
{
  "name":"itbluebox","age":3
}

<!--es8之前的版本跟上面有些微区别：

PUT /索引名/~类型名~/id
{请求体}

PUT /test1/type1/1
{"name":"itbluebox","age":3
} -->
```

返回：

```JSON
{
  "_index": "test1",
  "_id": "1",
  "_version": 1,
  "result": "created",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "_seq_no": 0,
  "_primary_term": 1
}
```

此时去head中查看多了一个索引![截屏2023-04-25 15.13.27](https://cdn.jsdelivr.net/gh/522923331/typora-image/img/%E6%88%AA%E5%B1%8F2023-04-25%2015.13.27.png)

## 3、索引指定字段类型

es中有以下几种字段类型：

- 字符串类型
  text 、 keyword
- 数值类型
  long, integer, short, byte, double, float, half float, scaled float
- 日期类型
  date
- 布尔值类型
  boolean
- 二进制类型
  binary

指定字段类型，创建规则，只创建索引不添加数据

```json
PUT /test2
{
  "mappings": {
    "properties": {
      "name":{
        "type": "text"
      },
      "age":{
        "type": "long"
      },
      "birthday":{
        "type": "date"
      }
    }
  }
}
```

响应结果

```json
{
  "acknowledged": true,
  "shards_acknowledged": true,
  "index": "test2"
}
```

## 4、查看索引

通过GET来获取索引信息

GET /test2

```json
{
  "test2": {
    "aliases": {},
    "mappings": {
      "properties": {
        "age": {
          "type": "long"
        },
        "birthday": {
          "type": "date"
        },
        "name": {
          "type": "text"
        }
      }
    },
    "settings": {
      "index": {
        "routing": {
          "allocation": {
            "include": {
              "_tier_preference": "data_content"
            }
          }
        },
        "number_of_shards": "1",
        "provided_name": "test2",
        "creation_date": "1682407744353",
        "number_of_replicas": "1",
        "uuid": "VUn98kyARYySIRLS2d8YKA",
        "version": {
          "created": "8070099"
        }
      }
    }
  }
}
```

## 5、获取其它信息(cat系列命令)

查询健康值：GET _cat/health

```yaml
# 获取集群状态
GET _cat/health
GET _cat/health?v # 当使用v参数时 会显示列名的详细信息
GET _cat/health?help # 这里对照不加help的命令可以显示每一列的信息说明
GET _cat/nodes?v # 显示所有的node信息
GET _cat/nodes?v&h=ip,load_5m # 只显示ip和load_5m这两列
GET _cat/indices?v&s=store.size:desc # 显示左右索引并按照存储大小排序
GET _cat/indices?v&format=json&pretty # 通过json格式显示输出
GET _cat/templates?v&s=order:desc,version:desc #列出所有templates,按照order降序,version降序
```

## 6、修改索引

### a.直接PUT覆盖（不推荐）（如果PUT的时候少字段会丢失数据）

先put一条数据，再put一条数据，注意观察对比put后的响应结果。

```json
PUT /test3/_doc/1
{"name":"蓝盒子itbluebox","age":13,"birth":"2022-11-3"
}
```

```json
PUT /test3/_doc/1
{"name":"蓝盒子itbluebox123","age":13,"birth":"2022-11-3"
}
```

```json
{
  "_index": "test3",
  "_id": "1",
  "_version": 3,  <!--put完后，版本号增加了-->
  "result": "updated",<!--result变成了updated-->
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "_seq_no": 2,
  "_primary_term": 1
}
```

如果我们put的时候，去掉age字段，那么去es head 数据浏览中发现，age字段没有了。

### b.通过post命令更新

对比put，post使用的其实是_update。put好像用不了。

```json
POST /test3/_update/1
{
  "doc":{"name":"张三"}
}
```

执行完，去 es head数量浏览中发现，成功修改了name的value，别的字段不受影响。

## 7、删除索引

DELETE test3  或者 DELETE /test3

## 8、删除文档

创建多条文档数据

```json
PUT /test3/_doc/1
{"name":"蓝盒子itbluebox111","age":13,"birth":"2022-11-3"
}
PUT /test3/_doc/2
{"name":"蓝盒子itbluebox222","age":13,"birth":"2022-11-3"
}
PUT /test3/_doc/3
{"name":"蓝盒子itbluebox333","age":13,"birth":"2022-11-3"
}
```

可以看到数据浏览test3索引中，有分别有id为1,2,3的三个文档。

![image-20230425164842226](https://cdn.jsdelivr.net/gh/522923331/typora-image/img/image-20230425164842226.png)

删除对应的文档：

```shell
DELETE /test3/_doc/1
```

# ElasticSearch 文档的基本操作

## 1.添加数据

```json
PUT /itbluebox/_doc/1
{
  "name": "蓝盒子itbluebox","age":23,   "desc":"一顿操作猛如虎，一看工资两千五！！！","tags":["技术宅","温暖","好东西"]
}
PUT /itbluebox/_doc/2
{
  "name": "蓝盒子张三","age":3,"desc":"法外狂徒","tags":["交友","旅游","乒乓球"]
}
PUT /itbluebox/_doc/3
{
  "name": "李四","age":15,"desc":"兵乓球、足球、滑旱冰、跑步、跳绳、举重等","tags":["听音乐","看电影","绘画"]
}
PUT /itbluebox/_doc/4
{
  "name": "王五","age":19,"desc":"做弹弓玩、做木剑玩、做橡皮枪玩","tags":["滑板","羽毛球","喜欢篮球"]
}
```

## 2.查询数据

### a.获取索引信息

```json
GET itbluebox
```

索引操作的时候，已经操作过了，不再赘述。

### b.查询所有文档数据

```json
GET itbluebox/_search
```

### c.查询一条文档数据，通过id查询

```json
GET itbluebox/_doc/1
```

### d.简单条件查询

```json
GET /itbluebox/_search?q=name:蓝盒子
```

### e.复杂查询

#### 1>直接匹配查询，match匹配

```json
GET /itbluebox/_search
{"query": { "match": {"name": "蓝盒子"}}
}
```



#### 2>_source过滤查询返回字段

设置只显示name和age：

```json
GET /itbluebox/_search
{"query": { "match": {"name": "蓝盒子"}},"_source": ["name","age"]
}
```



#### 3>排序查询（sort）

通过年龄进行降序排列

```json
GET /itbluebox/_search
{"query": {"match": {"name": "蓝盒子"}},"sort": [{"age": {"order": "desc"}}]
}
```

#### 4>分页查询（from,size）

from,size 相当于mysql数据库limit当中的两个参数

```json
GET /itbluebox/_search
{"query": { "match": {"name": "蓝盒子"}},"sort": [{"age": {"order": "asc"}}],"from": 0,"size": 2
}
```

#### 5>布尔值查询

**must：多条件精确查询**（**相当于mysql当中的and**），所有的条件都要符合（`where id = 1 and name = xxx`）

同理：**must_not：多条件精确查询**（**相当于mysql当中的!=**）

**should：多条件精确查询**（**相当于mysql当中的or**）

实现多条件查询：

```json
GET /itbluebox/_search
{"query": { "bool": {"must": [{"match": {"name": "蓝盒子"}},{"match": {"age": 13}}]}}
}
```

#### 6>配合filter实现复杂查询,相当于myslq的范围查询

```json
gt：大于
gte：大于等于
lt:小于
lte:小于等于

GET /itbluebox/_search
{"query": { "bool": {"must": [{"match": {"name": "蓝盒子"}}],"filter": [{"range": {"age": {"gte": 1,"lte": 20}}}]}}
}
```

#### 7>匹配多个搜索条件

比如tag：多个搜索条件用空格分隔，只要满足其中一个条件就可以被查询到

```json
GET /itbluebox/_search
{"query": { "match": {"tags": "球 技术"}}
}
```



#### 8>单个值匹配精确查询(term)

创建索引库

```json
PUT testdb
{"mappings": {"properties": {"name":{"type": "text"},"desc":{"type": "keyword"}}}
}

<!--添加一些数据-->

PUT testdb/_doc/1
{"name":"蓝盒子Java name","desc":"蓝盒子Java desc"
}
PUT testdb/_doc/2
{"name":"蓝盒子Java name","desc":"蓝盒子Java desc2"
}

```

term查询是直接通过倒排索引指定的词条进行精确的查询！

关于分词

- term，直接查找精确值
- match，会使用分词器进行解析！（先分析文档，然后在通过分析的文档进行查询！）

**两个类型 text keyword**

```yaml
GET _analyze
{"analyzer": "keyword","text": "蓝盒子Java name"
}
#响应结果：
{
  "tokens": [
    {
      "token": "蓝盒子Java name",
      "start_offset": 0,
      "end_offset": 12,
      "type": "word",
      "position": 0
    }
  ]
}
```

以上，从响应结果上可以看到，词没有被拆分

```yaml
GET _analyze
{"analyzer": "standard","text": "蓝盒子Java name"
}
#响应结果：
{
  "tokens": [
    {
      "token": "蓝",
      "start_offset": 0,
      "end_offset": 1,
      "type": "<IDEOGRAPHIC>",
      "position": 0
    },
    {
      "token": "盒",
      "start_offset": 1,
      "end_offset": 2,
      "type": "<IDEOGRAPHIC>",
      "position": 1
    },
    {
      "token": "子",
      "start_offset": 2,
      "end_offset": 3,
      "type": "<IDEOGRAPHIC>",
      "position": 2
    },
    {
      "token": "java",
      "start_offset": 3,
      "end_offset": 7,
      "type": "<ALPHANUM>",
      "position": 3
    },
    {
      "token": "name",
      "start_offset": 8,
      "end_offset": 12,
      "type": "<ALPHANUM>",
      "position": 4
    }
  ]
}
```

以上，可以看到，词被拆分了。

查询name当中有蓝的数据：因为name字段是text类型，在进行分词的时候会被分词器解析

```json
GET testdb/_search
{"query": {"term": {"name": "蓝"}}
}
```

所以结果就是上面put的两条数据都被查询了出来。

而desc是keyword类型，所以在进行搜索的時候没有进行分词，直接匹配：查询无结果

```yaml
GET testdb/_search
{"query": {"term": {"desc": "蓝"}}
}
#响应结果：
{
  "took": 1,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 0,
      "relation": "eq"
    },
    "max_score": null,
    "hits": []
  }
}
```

改成将全部的内容作为搜索，搜索出来了对应的信息。keyword字段类型不会被分词器解析。

```yaml
GET testdb/_search
{"query": {"term": {"desc": "蓝盒子Java desc2"}}
}
#响应结果：
{
  "took": 0,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 0.6931471,
    "hits": [
      {
        "_index": "testdb",
        "_id": "2",
        "_score": 0.6931471,
        "_source": {
          "name": "蓝盒子Java name",
          "desc": "蓝盒子Java desc2"
        }
      }
    ]
  }
}
```

#### 9>多个值匹配精确查询（term）

继续添加一些测试数据

```json
PUT testdb/_doc/3
{"t1":"22","t2":"2022-11-05"
}
PUT testdb/_doc/4
{"t1":"33","t2":"2022-11-06"
}
```

实现精确查询多个值

```json
GET testdb/_search
{"query": {"bool": {"should": [{"term": {"t1":"22"}},{"term": {"t1":"33"}}]}}
}
```



* 高亮显示（highlight）

  ```json
  GET itbluebox/_search
  {"query": {"match": {"name": "蓝盒子"}},"highlight": {"fields": {"name": {}}}
  }
  ```

* 自定义搜索高亮，不使用em（pre_tags前缀，post_tags后缀）

  ```json
  GET itbluebox/_search
  {"query": {"match": {"name": "蓝盒子"}},"highlight": {"pre_tags": "<span style='color:red'>", "post_tags": "</span>", "fields": {"name": {}}}
  }
  ```



## 3.更新数据

PUT【注意如果PUT不传递值，那么值就会被覆盖】

```json
PUT /itbluebox/_doc/1
{"name": "蓝盒子","age":23,   "desc":"一顿操作猛如虎，一看工资两千五！！！","tags":["技术宅","温暖","好东西"]
}
```

POST  更灵活

```json
POST /itbluebox/_doc/1
{"name": "疯狂的蓝盒子"
}
```